{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26abb37e-59a5-4832-91c6-49502b8933d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "session = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "time = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TurkuNLP/bert-base-finnish-uncased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03582e05-9063-4e27-b110-de3810625fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels, files = [], [], [\"FinnSentiment2020neg\", \"FinnSentiment2020neut\", \"FinnSentiment2020pos\"]\n",
    "for i, file in enumerate(files):\n",
    "    with open(f\"E:/Emodim/data/tr/{file}.txt\", \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "        texts.extend(lines), labels.extend([i]*len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca875fe-2d2a-4b4a-a16e-3dfe7d389434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "token_lens = []\n",
    "for txt in texts:\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))\n",
    "max_length=np.max(token_lens)\n",
    "print(max_length)\n",
    "MAX_LEN = max_length + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf9c061-98cb-4132-8f14-a05ba22442aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=.1)\n",
    "\n",
    "\n",
    "def tokenize(data, max_len=MAX_LEN) :\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for i in range(len(data)):\n",
    "        encoded = tokenizer.encode_plus(data[i], add_special_tokens=True, max_length=max_len, padding='max_length', return_attention_mask=True)\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return np.array(input_ids), np.array(attention_masks)\n",
    "\n",
    "train_input_ids, train_attention_masks = tokenize(train_texts, MAX_LEN)\n",
    "val_input_ids, val_attention_masks = tokenize(val_texts, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2296c10b-f900-436b-9e6d-0e997b033b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import train_test_split\\n\\n\\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=.1)\\ntrain_labels = np.array(train_labels)\\nval_labels = np.array(val_labels)\\n# train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors=tf)\\n# val_encodings = tokenizer(val_texts, truncation=True, padding=True, return_tensors=tf)\\n\\ntrain_dataset = tokenizer(train_texts, truncation=True, padding=True, return_tensors=\"tf\")\\nval_dataset = tokenizer(val_texts, truncation=True, padding=True, return_tensors=\"tf\")\\ntrain_dataset = train_dataset.data\\nval_dataset = val_dataset.data\\n# train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels))\\n# val_dataset = tf.data.Dataset.from_tensor_slices((dict(val_encodings),val_labels))\\n\\n\\ntrain_encodings = tokenizer.batch_encode_plus(train_texts,\\n                                              max_length=MAX_SEQUENCE_LENGTH, # set the length of the sequences\\n                                              add_special_tokens=True, # add [CLS] and [SEP] tokens\\n                                              return_attention_mask=True,\\n                                              return_token_type_ids=False, # not needed for this type of ML task\\n                                              truncation=True,\\n                                              padding=\\'longest\\', # add 0 pad tokens to the sequences less than max_length\\n                                              return_tensors=\\'tf\\')\\nval_encodings = tokenizer.batch_encode_plus(val_texts,\\n                                            max_length=MAX_SEQUENCE_LENGTH, # set the length of the sequences\\n                                            add_special_tokens=True, # add [CLS] and [SEP] tokens\\n                                            return_attention_mask=True,\\n                                            return_token_type_ids=False, # not needed for this type of ML task\\n                                            truncation=True,\\n                                            padding=\\'longest\\', # add 0 pad tokens to the sequences less than max_length\\n                                            return_tensors=\\'tf\\')\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=.1)\n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)\n",
    "# train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors=tf)\n",
    "# val_encodings = tokenizer(val_texts, truncation=True, padding=True, return_tensors=tf)\n",
    "\n",
    "train_dataset = tokenizer(train_texts, truncation=True, padding=True, return_tensors=\"tf\")\n",
    "val_dataset = tokenizer(val_texts, truncation=True, padding=True, return_tensors=\"tf\")\n",
    "train_dataset = train_dataset.data\n",
    "val_dataset = val_dataset.data\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels))\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((dict(val_encodings),val_labels))\n",
    "\n",
    "\n",
    "train_encodings = tokenizer.batch_encode_plus(train_texts,\n",
    "                                              max_length=MAX_SEQUENCE_LENGTH, # set the length of the sequences\n",
    "                                              add_special_tokens=True, # add [CLS] and [SEP] tokens\n",
    "                                              return_attention_mask=True,\n",
    "                                              return_token_type_ids=False, # not needed for this type of ML task\n",
    "                                              truncation=True,\n",
    "                                              padding='longest', # add 0 pad tokens to the sequences less than max_length\n",
    "                                              return_tensors='tf')\n",
    "val_encodings = tokenizer.batch_encode_plus(val_texts,\n",
    "                                            max_length=MAX_SEQUENCE_LENGTH, # set the length of the sequences\n",
    "                                            add_special_tokens=True, # add [CLS] and [SEP] tokens\n",
    "                                            return_attention_mask=True,\n",
    "                                            return_token_type_ids=False, # not needed for this type of ML task\n",
    "                                            truncation=True,\n",
    "                                            padding='longest', # add 0 pad tokens to the sequences less than max_length\n",
    "                                            return_tensors='tf')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c99b973-79d0-4576-9494-270988c5e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"TurkuNLP/bert-base-finnish-uncased-v1\")\n",
    "# bert_model = TFBertForSequenceClassification.from_pretrained(\"TurkuNLP/bert-base-finnish-uncased-v1\", output_hidden_states=True, num_labels=3)\n",
    "#input_ids = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_ids')\n",
    "#attention_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='attention_mask')\n",
    "#output = bert_model([input_ids, attention_mask])[0]\n",
    "#output = tf.keras.layers.Dense(3, activation='softmax')(output)\n",
    "#model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c823a32-dcf2-42d4-9863-0c4d32652037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def build_classifier_model():\n",
    "    input_ids = tf.keras.Input(shape=(128, ),dtype='int32')\n",
    "    attention_mask = tf.keras.Input(shape=(128, ), dtype='int32')\n",
    "\n",
    "    transformer = model([input_ids, attention_mask])    \n",
    "    hidden_states = transformer[1] # get output_hidden_states\n",
    "    \n",
    "    hidden_states_size = 4 # count of the last states \n",
    "    hiddes_states_ind = list(range(-hidden_states_size, 0, 1))\n",
    "\n",
    "    selected_hiddes_states = tf.keras.layers.concatenate(tuple([hidden_states[i] for i in hiddes_states_ind]))\n",
    "\n",
    "    X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(net)\n",
    "    X = tf.keras.layers.Concatenate(axis=-1)([X, input_layer])\n",
    "    X = tf.keras.layers.MaxPooling1D(20)(X)\n",
    "    X = tf.keras.layers.SpatialDropout1D(0.4)(X)\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    X = tf.keras.layers.Dense(128, activation=\"relu\")(X)\n",
    "    X = tf.keras.layers.Dropout(0.25)(X)\n",
    "    X = tf.keras.layers.Dense(3, activation='softmax')(X)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)\n",
    "        for layer in model.layers[:3]:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "def create_model(bert_model, max_len=MAX_LEN):\n",
    "    \n",
    "    opt = tfa.optimizers.AdamW(learning_rate=1e-5, weight_decay=1e-7)\n",
    "    # opt = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-7)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False)\n",
    "    accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    input_ids = tf.keras.Input(shape=(max_len,), dtype='int32')\n",
    "    attention_masks = tf.keras.Input(shape=(max_len,), dtype='int32')\n",
    "    embeddings = bert_model.bert([input_ids, attention_masks])[1]\n",
    "    output = tf.keras.layers.Dense(3, activation=\"softmax\")(embeddings)\n",
    "    model = tf.keras.models.Model(inputs = [input_ids, attention_masks], outputs = output)\n",
    "    model.compile(opt, loss=loss, metrics=accuracy)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62b89312-c4d0-4e4a-a8e0-d20c0e5d6916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_7/bert/encoder/layer_._4/attention/self/Softmax' defined at (most recent call last):\n    File \"E:\\Miniconda\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"E:\\Miniconda\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in dispatch_queue\n      await self.process_one()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 497, in process_one\n      await dispatch(*args)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 404, in dispatch_shell\n      await result\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 728, in execute_request\n      reply_content = await reply_content\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\aapos\\AppData\\Local\\Temp\\ipykernel_18996\\2225564236.py\", line 5, in <cell line: 5>\n      history_bert = model.fit([train_input_ids, train_attention_masks], np.array(train_labels),\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1640, in run_call_with_unpacked_inputs\n      from_pipeline = kwargs.pop(\"_from_pipeline\", None)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 869, in call\n      encoder_outputs = self.encoder(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 554, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 560, in call\n      layer_outputs = layer_module(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 470, in call\n      self_attention_outputs = self.attention(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 386, in call\n      self_outputs = self.self_attention(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 325, in call\n      attention_probs = stable_softmax(logits=attention_scores, axis=-1)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\tf_utils.py\", line 70, in stable_softmax\n      return tf.nn.softmax(logits=logits + 1e-9, axis=axis, name=name)\nNode: 'model_7/bert/encoder/layer_._4/attention/self/Softmax'\nOOM when allocating tensor with shape[32,12,198,198] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_7/bert/encoder/layer_._4/attention/self/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_91677]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# model.summary()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m history_bert \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_attention_masks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_attention_masks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_7/bert/encoder/layer_._4/attention/self/Softmax' defined at (most recent call last):\n    File \"E:\\Miniconda\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"E:\\Miniconda\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in dispatch_queue\n      await self.process_one()\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 497, in process_one\n      await dispatch(*args)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 404, in dispatch_shell\n      await result\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 728, in execute_request\n      reply_content = await reply_content\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\aapos\\AppData\\Local\\Temp\\ipykernel_18996\\2225564236.py\", line 5, in <cell line: 5>\n      history_bert = model.fit([train_input_ids, train_attention_masks], np.array(train_labels),\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1640, in run_call_with_unpacked_inputs\n      from_pipeline = kwargs.pop(\"_from_pipeline\", None)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 869, in call\n      encoder_outputs = self.encoder(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 554, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 560, in call\n      layer_outputs = layer_module(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 470, in call\n      self_attention_outputs = self.attention(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 386, in call\n      self_outputs = self.self_attention(\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 325, in call\n      attention_probs = stable_softmax(logits=attention_scores, axis=-1)\n    File \"E:\\Miniconda\\envs\\tf\\lib\\site-packages\\transformers\\tf_utils.py\", line 70, in stable_softmax\n      return tf.nn.softmax(logits=logits + 1e-9, axis=axis, name=name)\nNode: 'model_7/bert/encoder/layer_._4/attention/self/Softmax'\nOOM when allocating tensor with shape[32,12,198,198] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_7/bert/encoder/layer_._4/attention/self/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_91677]"
     ]
    }
   ],
   "source": [
    "model = create_model(bert_model, MAX_LEN)\n",
    "# model.summary()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "history_bert = model.fit([train_input_ids, train_attention_masks], np.array(train_labels), \n",
    "                         validation_data=([val_input_ids, val_attention_masks], np.array(val_labels)), \n",
    "                         epochs=4, batch_size=64, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae389c6-f3f1-49b9-a36b-d06647345f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "model.compile(optimizer = tfa.optimizers.AdamW(learning_rate=5e-4, weight_decay=0.01),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
    "              metrics = tf.keras.metrics.SparseCategoricalAccuracy())\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "# model.fit(train_dataset.shuffle(1000).batch(16), callbacks=[early_stop], epochs=5, batch_size=16)\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, callbacks=[early_stop], epochs=5)\n",
    "\n",
    "history = model.fit(x=train_encodings.values(),\n",
    "                    y=np.array(train_labels), \n",
    "                    validation_data=(val_encodings.values(), np.array(val_labels)),  \n",
    "                    callbacks=[early_stop], \n",
    "                    epochs=5)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288934a-3afd-4654-a328-43614538c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = f'D:\\Work\\Models\\fine_tuned_finBERT_tf_{time}_2\\\\1'\n",
    "# modelpath = f'E:\\Emodim\\data\\others\\\\fine_tuned_finBERT_tf_14-06-2022_12-00-22\\\\1'\n",
    "model.save(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0fda84-729c-4305-828a-f2a3434e6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_model = tf.keras.models.load_model(f\"{modelpath}\")\n",
    "import_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9faeb9-8178-44c7-80ca-46644388709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "n = 50\n",
    "inputs = []\n",
    "with open(f\"D:\\\\Work\\\\Data\\\\s24_2001_sentences_shuffled_slice.txt\", 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    random.shuffle(lines)\n",
    "    for line in lines:\n",
    "        inputs.append(line.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d29cd2-100e-41bb-975a-1abef3f2e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for inp in inputs[:n]:\n",
    "    input_text_tokenized = tokenizer.encode(inp, truncation=True, padding=True, return_tensors=\"tf\")\n",
    "    prediction = import_model(input_text_tokenized)\n",
    "    prediction_logits = prediction[0]\n",
    "    prediction_probs = tf.nn.softmax(prediction_logits,axis=1).numpy()\n",
    "    print(f'Sentence: {inp}, Probabilities: {prediction_probs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5722131b-7499-4106-ac95-ee9b253da7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for inp in inputs[:n]:\n",
    "    text = tokenizer.encode(inp,\n",
    "                          truncation=True,\n",
    "                          padding=True,\n",
    "                          return_tensors=\"tf\")\n",
    "    print(inp, text)\n",
    "    prediction = model(text)\n",
    "    prediction_logits = prediction[0]\n",
    "    prediction_probs = tf.nn.softmax(prediction_logits,axis=1).numpy()\n",
    "    print(f'Sentence: {inp}, Probabilities: {prediction_probs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
