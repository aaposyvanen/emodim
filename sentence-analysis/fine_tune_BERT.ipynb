{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaposyvanen/emodim/blob/master/sentence-analysis/fine_tune_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load FinBERT from huggingface"
      ],
      "metadata": {
        "id": "TSXdLr6gj5U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import onnx\n",
        "from onnx_tf.backend import prepare"
      ],
      "metadata": {
        "id": "L6wKpI9KmdKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VRjEcexbcXev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d48626-856f-4d4f-c396-4e63e10c4514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Device name: /device:GPU:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at TurkuNLP/bert-base-finnish-cased-v1 were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at TurkuNLP/bert-base-finnish-cased-v1.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(f\"Device name: {device_name}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"TurkuNLP/bert-base-finnish-cased-v1\", cache_dir=\"finBERT/\")\n",
        "model = TFAutoModel.from_pretrained(\"TurkuNLP/bert-base-finnish-cased-v1\", cache_dir=\"finBERT/\")\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Luq8FccrKTzv",
        "outputId": "b90ce72e-4ca1-468b-9877-53fea22c2043"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download trainingdata"
      ],
      "metadata": {
        "id": "P4qeRpg_dc0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "file_names = ['combinedneg.txt', 'combinedneut2.txt', 'combinedpos.txt']\n",
        "data, labels = [], []\n",
        "for i, file in enumerate(file_names):\n",
        "  r = requests.get(f\"https://raw.githubusercontent.com/aaposyvanen/emodim/master/data/tr/{file}\")\n",
        "  data.extend(r.text.split('\\n'))\n",
        "  labels.extend([i]*len(r.text.split('\\n')))\n",
        "np.array(data), np.array(labels)\n",
        "sentences = data\n",
        "# sentences = pd.DataFrame(zip(data, labels))"
      ],
      "metadata": {
        "id": "BEpGx9eze8M2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(' Original: ', sentences[0])\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q67w_uBNv7PH",
        "outputId": "e3b6cb92-f81d-4368-e546-ee5eae236ac0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  ei mit채채n muttia.\n",
            "Tokenized:  ['ei', 'mit채채n', 'mut', '##tia', '.']\n",
            "Token IDs:  [193, 642, 1851, 570, 111]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "for sent in sentences:\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUNWr2yu84tc",
        "outputId": "4f08195f-82b2-440e-c810-3ed408a34a24"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "      sent,                         # Sentence to encode.\n",
        "      add_special_tokens = True,    # Add '[CLS]' and '[SEP]'\n",
        "      max_length = max_len,         # Pad & truncate all sentences.\n",
        "      pad_to_max_length = True,\n",
        "      return_attention_mask = True, # Construct attn. masks.\n",
        "      return_tensors = 'pt'         # Return pt tensors.\n",
        "      )\n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJmeGFrY9IEZ",
        "outputId": "4664fa50-63dd-42a0-ce07-32b4066affb2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  ei mit채채n muttia.\n",
            "Token IDs: tensor([ 102,  193,  642, 1851,  570,  111,  103,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5TH_tAXWohM",
        "outputId": "ab74d1af-f744-430e-e062-41cd1ade0b3e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30,726 training samples\n",
            "3,414 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "xB1CQu7JW7z3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"TurkuNLP/bert-base-finnish-cased-v1\",\n",
        "    num_labels = 3,\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jza9nknCW_R8",
        "outputId": "58ce0bcc-f5fb-4dee-f2de-cad583b02c6e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at TurkuNLP/bert-base-finnish-cased-v1 were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-cased-v1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(50105, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQt2zu0YXbI5",
        "outputId": "ecf05a6a-65d9-45da-cd51-7e6968c08cce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (50105, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (3, 768)\n",
            "classifier.bias                                                 (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dogOKSnXijl",
        "outputId": "7c6cdf5b-abd8-4429-9107-ebb849d03361"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        output = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask, \n",
        "                     labels=b_labels)\n",
        "        loss = output[0]\n",
        "        logits = output[1]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            output = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "            loss = output[0]\n",
        "            logits = output[1]\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-8fkU4sXook",
        "outputId": "83f569d6-357d-411f-87f4-83f266971e65"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    961.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    961.    Elapsed: 0:00:35.\n",
            "  Batch   120  of    961.    Elapsed: 0:00:53.\n",
            "  Batch   160  of    961.    Elapsed: 0:01:12.\n",
            "  Batch   200  of    961.    Elapsed: 0:01:30.\n",
            "  Batch   240  of    961.    Elapsed: 0:01:49.\n",
            "  Batch   280  of    961.    Elapsed: 0:02:07.\n",
            "  Batch   320  of    961.    Elapsed: 0:02:25.\n",
            "  Batch   360  of    961.    Elapsed: 0:02:43.\n",
            "  Batch   400  of    961.    Elapsed: 0:03:02.\n",
            "  Batch   440  of    961.    Elapsed: 0:03:20.\n",
            "  Batch   480  of    961.    Elapsed: 0:03:38.\n",
            "  Batch   520  of    961.    Elapsed: 0:03:56.\n",
            "  Batch   560  of    961.    Elapsed: 0:04:15.\n",
            "  Batch   600  of    961.    Elapsed: 0:04:33.\n",
            "  Batch   640  of    961.    Elapsed: 0:04:51.\n",
            "  Batch   680  of    961.    Elapsed: 0:05:09.\n",
            "  Batch   720  of    961.    Elapsed: 0:05:28.\n",
            "  Batch   760  of    961.    Elapsed: 0:05:46.\n",
            "  Batch   800  of    961.    Elapsed: 0:06:04.\n",
            "  Batch   840  of    961.    Elapsed: 0:06:22.\n",
            "  Batch   880  of    961.    Elapsed: 0:06:41.\n",
            "  Batch   920  of    961.    Elapsed: 0:06:59.\n",
            "  Batch   960  of    961.    Elapsed: 0:07:17.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epoch took: 0:07:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.42\n",
            "  Validation took: 0:00:17\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    961.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    961.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    961.    Elapsed: 0:00:55.\n",
            "  Batch   160  of    961.    Elapsed: 0:01:13.\n",
            "  Batch   200  of    961.    Elapsed: 0:01:31.\n",
            "  Batch   240  of    961.    Elapsed: 0:01:49.\n",
            "  Batch   280  of    961.    Elapsed: 0:02:08.\n",
            "  Batch   320  of    961.    Elapsed: 0:02:26.\n",
            "  Batch   360  of    961.    Elapsed: 0:02:44.\n",
            "  Batch   400  of    961.    Elapsed: 0:03:02.\n",
            "  Batch   440  of    961.    Elapsed: 0:03:21.\n",
            "  Batch   480  of    961.    Elapsed: 0:03:39.\n",
            "  Batch   520  of    961.    Elapsed: 0:03:57.\n",
            "  Batch   560  of    961.    Elapsed: 0:04:15.\n",
            "  Batch   600  of    961.    Elapsed: 0:04:34.\n",
            "  Batch   640  of    961.    Elapsed: 0:04:52.\n",
            "  Batch   680  of    961.    Elapsed: 0:05:10.\n",
            "  Batch   720  of    961.    Elapsed: 0:05:28.\n",
            "  Batch   760  of    961.    Elapsed: 0:05:47.\n",
            "  Batch   800  of    961.    Elapsed: 0:06:05.\n",
            "  Batch   840  of    961.    Elapsed: 0:06:23.\n",
            "  Batch   880  of    961.    Elapsed: 0:06:41.\n",
            "  Batch   920  of    961.    Elapsed: 0:07:00.\n",
            "  Batch   960  of    961.    Elapsed: 0:07:18.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epoch took: 0:07:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:00:17\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    961.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    961.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    961.    Elapsed: 0:00:55.\n",
            "  Batch   160  of    961.    Elapsed: 0:01:13.\n",
            "  Batch   200  of    961.    Elapsed: 0:01:31.\n",
            "  Batch   240  of    961.    Elapsed: 0:01:49.\n",
            "  Batch   280  of    961.    Elapsed: 0:02:08.\n",
            "  Batch   320  of    961.    Elapsed: 0:02:26.\n",
            "  Batch   360  of    961.    Elapsed: 0:02:44.\n",
            "  Batch   400  of    961.    Elapsed: 0:03:02.\n",
            "  Batch   440  of    961.    Elapsed: 0:03:21.\n",
            "  Batch   480  of    961.    Elapsed: 0:03:39.\n",
            "  Batch   520  of    961.    Elapsed: 0:03:57.\n",
            "  Batch   560  of    961.    Elapsed: 0:04:15.\n",
            "  Batch   600  of    961.    Elapsed: 0:04:34.\n",
            "  Batch   640  of    961.    Elapsed: 0:04:52.\n",
            "  Batch   680  of    961.    Elapsed: 0:05:10.\n",
            "  Batch   720  of    961.    Elapsed: 0:05:29.\n",
            "  Batch   760  of    961.    Elapsed: 0:05:47.\n",
            "  Batch   800  of    961.    Elapsed: 0:06:05.\n",
            "  Batch   840  of    961.    Elapsed: 0:06:23.\n",
            "  Batch   880  of    961.    Elapsed: 0:06:42.\n",
            "  Batch   920  of    961.    Elapsed: 0:07:00.\n",
            "  Batch   960  of    961.    Elapsed: 0:07:18.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epoch took: 0:07:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.53\n",
            "  Validation took: 0:00:17\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    961.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    961.    Elapsed: 0:00:37.\n",
            "  Batch   120  of    961.    Elapsed: 0:00:55.\n",
            "  Batch   160  of    961.    Elapsed: 0:01:13.\n",
            "  Batch   200  of    961.    Elapsed: 0:01:31.\n",
            "  Batch   240  of    961.    Elapsed: 0:01:50.\n",
            "  Batch   280  of    961.    Elapsed: 0:02:08.\n",
            "  Batch   320  of    961.    Elapsed: 0:02:26.\n",
            "  Batch   360  of    961.    Elapsed: 0:02:45.\n",
            "  Batch   400  of    961.    Elapsed: 0:03:03.\n",
            "  Batch   440  of    961.    Elapsed: 0:03:21.\n",
            "  Batch   480  of    961.    Elapsed: 0:03:40.\n",
            "  Batch   520  of    961.    Elapsed: 0:03:58.\n",
            "  Batch   560  of    961.    Elapsed: 0:04:16.\n",
            "  Batch   600  of    961.    Elapsed: 0:04:34.\n",
            "  Batch   640  of    961.    Elapsed: 0:04:53.\n",
            "  Batch   680  of    961.    Elapsed: 0:05:11.\n",
            "  Batch   720  of    961.    Elapsed: 0:05:29.\n",
            "  Batch   760  of    961.    Elapsed: 0:05:48.\n",
            "  Batch   800  of    961.    Elapsed: 0:06:06.\n",
            "  Batch   840  of    961.    Elapsed: 0:06:24.\n",
            "  Batch   880  of    961.    Elapsed: 0:06:43.\n",
            "  Batch   920  of    961.    Elapsed: 0:07:01.\n",
            "  Batch   960  of    961.    Elapsed: 0:07:19.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epoch took: 0:07:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.64\n",
            "  Validation took: 0:00:17\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:30:22 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PTpmkXotZV1g",
        "outputId": "1505840c-2825-442b-e693-03ef53ecdbf0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.49         0.42           0.83       0:07:17         0:00:17\n",
              "2               0.28         0.43           0.84       0:07:18         0:00:17\n",
              "3               0.15         0.53           0.84       0:07:18         0:00:17\n",
              "4               0.08         0.64           0.85       0:07:19         0:00:17"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-053820f7-52c7-43f0-ae13-5cb0c39b20b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.49</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:07:17</td>\n",
              "      <td>0:00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.28</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:07:18</td>\n",
              "      <td>0:00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:07:18</td>\n",
              "      <td>0:00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.08</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:07:19</td>\n",
              "      <td>0:00:17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-053820f7-52c7-43f0-ae13-5cb0c39b20b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-053820f7-52c7-43f0-ae13-5cb0c39b20b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-053820f7-52c7-43f0-ae13-5cb0c39b20b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "TCMpGYsBZZXK",
        "outputId": "73cec8db-6428-4b57-e6bc-eeb51bf36659"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'ft_finBERT.pth')"
      ],
      "metadata": {
        "id": "Z8ETf7v-lx6Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def create_model(num_labels):\n",
        "    model_layers = tf.keras.Sequential([\n",
        "        encoder,\n",
        "        tf.keras.layers.Embedding(input_dim=len(encoder.get_vocabulary()), output_dim=32, embeddings_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4), mask_zero=False),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout=0.1, return_sequences=True)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout=0.1)),\n",
        "        tf.keras.layers.Dropout(0.10),\n",
        "        tf.keras.layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4), activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.10),\n",
        "        tf.keras.layers.Dense(num_labels),\n",
        "        tf.keras.layers.Activation('softmax')])\n",
        "    return model_layers\n",
        "'''"
      ],
      "metadata": {
        "id": "xzH6NCh7n2Li",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "fb0aab0c-69d0-4d93-ab59-61302cb9dfb8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef create_model(num_labels):\\n    model_layers = tf.keras.Sequential([\\n        encoder,\\n        tf.keras.layers.Embedding(input_dim=len(encoder.get_vocabulary()), output_dim=32, embeddings_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4), mask_zero=False),\\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout=0.1, return_sequences=True)),\\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout=0.1)),\\n        tf.keras.layers.Dropout(0.10),\\n        tf.keras.layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4), activation='relu'),\\n        tf.keras.layers.Dropout(0.10),\\n        tf.keras.layers.Dense(num_labels),\\n        tf.keras.layers.Activation('softmax')])\\n    return model_layers\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "fine_tuning_model = create_model(num_labels=3)\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n",
        "fine_tuning_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adamax(0.005),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "    metrics=['accuracy'])\n",
        "history = model.fit(train_dataset, validation_data=test_dataset, callbacks=[early_stop], epochs=30)\n",
        "fine_tuning_model.summary()\n",
        "'''"
      ],
      "metadata": {
        "id": "t2fojjEQn7OI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b12fd20e-a815-434a-cb9d-4d8efe0ed861"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfine_tuning_model = create_model(num_labels=3)\\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\\nfine_tuning_model.compile(\\n    optimizer=tf.keras.optimizers.Adamax(0.005),\\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\\n    metrics=['accuracy'])\\nhistory = model.fit(train_dataset, validation_data=test_dataset, callbacks=[early_stop], epochs=30)\\nfine_tuning_model.summary()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "6921ad156b59c3e3257790aa2ba9a1e99af3719b2ff9f98241a5afac940b227d"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 ('emodim')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "fine-tune_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}