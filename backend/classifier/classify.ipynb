{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dir = '..\\\\data'\n",
    "train_dir = f\"{dataset_dir}\\\\train\"\n",
    "test_dir = f\"{dataset_dir}\\\\test\"\n",
    "# train_dir = f\"{dataset_dir}\\\\tr\"\n",
    "# test_dir = f\"{dataset_dir}\\\\t\"\n",
    "batch_size = 32\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13567 files belonging to 3 classes.\n",
      "Using 10854 files for training.\n",
      "Found 13433 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = preprocessing.text_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "test_dataset = preprocessing.text_dataset_from_directory(\n",
    "    test_dir, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  b'S.V.S tuumaat ajatuksesta.??'\n",
      "Label: 1\n",
      "Sentence:  b'Multa ainaskii mukavia unijukan kuvia kaikille:)))'\n",
      "Label: 2\n",
      "Sentence:  b'Jauhoista ei puhuttu mit\\xc3\\xa4\\xc3\\xa4n, mutta se nyt oli taas sivuseikka.........'\n",
      "Label: 1\n",
      "Sentence:  b'suht tuore leffa..'\n",
      "Label: 1\n",
      "Sentence:  b'Kovin on suppea sanavarastosikin; \"sommiporo\", \"Buahhahhaahaaa\" jne.'\n",
      "Label: 0\n",
      "Sentence:  b'Toinen kaste, toinen henki'\n",
      "Label: 1\n",
      "Sentence:  b'Siihen asti, tutustukaa paikkoihin ja nauttikaa olostanne!'\n",
      "Label: 2\n",
      "Sentence:  b'Ja voiko n\\xc3\\xa4pp\\xc3\\xa4imist\\xc3\\xb6\\xc3\\xa4 k\\xc3\\xa4ytt\\xc3\\xa4\\xc3\\xa4 pelien pelaamiseen?'\n",
      "Label: 1\n",
      "Sentence:  b'Suosittelen Artiklan kursseja l\\xc3\\xa4mpim\\xc3\\xa4sti! :)'\n",
      "Label: 2\n",
      "Sentence:  b'Kiitos viel\\xc3\\xa4 ehdin muuttaa tiettyyn hotelliin..'\n",
      "Label: 2\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_dataset.take(1):\n",
    "    for i in range(10):\n",
    "        print(\"Sentence: \", text_batch.numpy()[i])\n",
    "        print(\"Label:\", label_batch.numpy()[i])\n",
    "example = train_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  [b'JA huom!'\n",
      " b'Ilmiantokulttuuri kaikessa vastenmielisyydess\\xc3\\xa4\\xc3\\xa4n on t\\xc3\\xb6rke\\xc3\\xa4t\\xc3\\xa4 riippumatta aiheesta.'\n",
      " b'Tavallisesti k\\xc3\\xa4ytetyiss\\xc3\\xa4 valaistuksissa, alle 300\\xe2\\x80\\x93500 lx, l\\xc3\\xa4mpim\\xc3\\xa4t s\\xc3\\xa4vyt koetaan luonteviksi.']\n",
      "Label: [1 0 1]\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_dataset.take(1):\n",
    "    print(\"Sentence: \", text_batch.numpy()[:3])\n",
    "    print(\"Label:\", label_batch.numpy()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to neg\n",
      "Label 1 corresponds to neut\n",
      "Label 2 corresponds to pos\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(train_dataset.class_names):\n",
    "    print(\"Label\", i, \"corresponds to\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  b'Onko kukaan lukenut sit\\xc3\\xa4 juttua?'\n",
      "Label: 1\n",
      "Sentence:  b'Hiano mies varmana k\\xc3\\xa4yn keikalla jatkossakin!!'\n",
      "Label: 2\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = TextVectorization(max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))\n",
    "for text_batch, label_batch in train_dataset.take(1):\n",
    "    for i in range(2):\n",
    "        print(\"Sentence: \", text_batch.numpy()[i])\n",
    "        print(\"Label:\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' '[UNK]' 'ja' 'on' 'ei' 'että' 'se' 'kun' 'niin' 'mutta' 'jos' 'ole'\n",
      " 'en' 'tai' 'olen' 'voi' 'kuin' 'nyt' 'oli' 'sen']\n"
     ]
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "print(vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6  17   4   1  11   1   1   1  39   3   1   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [ 84   1   1   1   1  57   1   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [447   1   1   1   1 293  12   1   1  99   1   1  57 560 228   1   0   0\n",
      "    0   0   0]]\n",
      "Original:  b'Se nyt ei tietenk\\xc3\\xa4\\xc3\\xa4n ole rikos - kukapa meist\\xc3\\xa4 aina on herttainen?'\n",
      "Round-trip:  se nyt ei [UNK] ole [UNK] [UNK] [UNK] aina on [UNK]          \n",
      "\n",
      "Original:  b'M\\xc3\\xa4 tulin pelonsekaisin tuntein katsoon, onko novellini poistettu.'\n",
      "Round-trip:  mä [UNK] [UNK] [UNK] [UNK] onko [UNK] [UNK]             \n",
      "\n",
      "Original:  b'-Meille kaapelitaloudessa asuville laitetaan maksuja, joita en aio taatusti ilman taistelua maksaa..Hmm. Onko kokemuksia t\\xc3\\xa4st\\xc3\\xa4 sis\\xc3\\xa4antennista?'\n",
      "Round-trip:  meille [UNK] [UNK] [UNK] [UNK] joita en [UNK] [UNK] ilman [UNK] [UNK] onko kokemuksia tästä [UNK]     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_dataset.take(1):\n",
    "    encoded_example = encoder(text_batch)[:3].numpy()\n",
    "    print(encoded_example)\n",
    "    for n in range(3):\n",
    "        print(\"Original: \", text_batch[n].numpy())\n",
    "        print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])\n",
    "print([layer.supports_masking for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01384239  0.01422525 -0.00378018]\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "Kyllä nelivetoinen on huonolla kelillä vakaampi ajaa kuin kaksivetoinen. \n",
    "on helvetin hyvä ajettava niin kuivalla kuin liukkallakin kelillä. Saattaahan neliveto olla parempi, mutta takavetosella on pärjätty, ja pärjätään, tosi hyvin. Itse en kaipaa nelivetoa, mutta jos joku tuntee olonsa turvallisemmaksi niin siitä vaan! \n",
    "mitähän mahdat tarkoittaa tolla vakaampi ajaa?? suurin merkitys on kyllä itse autolla vrt. paska/keskinkertainen neliveto vs hyvä etuveto. Ei esim audin nelivedot mitenkään ajettavuudella loista muiden yläpuolella. \n",
    "\"\"\"\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01384239  0.01422524 -0.00378018]\n"
     ]
    }
   ],
   "source": [
    "padding = \"the \" * 2000\n",
    "predictions = model.predict(np.array([sample_text, padding]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "340/340 [==============================] - 32s 61ms/step - loss: 0.8702 - accuracy: 0.7298 - val_loss: 0.7655 - val_accuracy: 0.7427\n",
      "Epoch 2/50\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.7817 - accuracy: 0.7314 - val_loss: 0.7374 - val_accuracy: 0.7417\n",
      "Epoch 3/50\n",
      "340/340 [==============================] - 16s 46ms/step - loss: 0.7585 - accuracy: 0.7318 - val_loss: 0.7149 - val_accuracy: 0.7510\n",
      "Epoch 4/50\n",
      "177/340 [==============>...............] - ETA: 7s - loss: 0.7383 - accuracy: 0.7378"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=50,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
